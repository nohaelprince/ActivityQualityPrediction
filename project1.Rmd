---
title: "Prediction of Quality of Active Work"
author: "Noha Elprince"
date: "November 23, 2014"
output: html_document
---
## Summary

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit, it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions:

exactly according to the specification (Class A)
throwing the elbows to the front (Class B)
lifting the dumbbell only halfway (Class C)
lowering the dumbbell only halfway (Class D)
throwing the hips to the front (Class E)

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. 

The data for this project come from this source: <http://groupware.les.inf.puc-rio.br/har>

The main objectives of this project are as follows

* Predict the manner in which they did the exercise
* Build a prediction model
* Calculate the out of sample error.
* Use the prediction model to predict 20 different test cases provided


## Load Data
```{r, echo=TRUE}
  training <- read.csv(file="./data/pml-training.csv", head=TRUE, na.strings=c("NA",""))
  testing <- read.csv(file="data/pml-testing.csv", head=TRUE, na.strings=c("NA",""))
  dim(training)   #[1] 19622   160
  dim(testing)    #[1]  20 160
  # str(training)
```

The dataset comprises `r ncol(testing)` features and `r  nrow(training)` observations in the training set and  `r  nrow(testing)` test cases in the testing set.

## Processing data
First, we check how many columns have NA values in the training and testing data and what is the quantity of NA values present.

```{r, echo=TRUE}
   sum(is.na(training)) #[1] 1921600
   sum(is.na(testing))  #[1] 2000 
```

we are going to ignore NA values using the following code segment

```{r, echo=TRUE}
# for training dataset
columnNACounts <- colSums(is.na(training)) 
# columnNACounts 
# after checking columnNACounts , we noticed:
# most columns with NA values have sum of NA values exceeeds 19200 
badColumns <- columnNACounts >= 19200           
cleanTrainingdata <- training[!badColumns]        
sum(is.na(cleanTrainingdata)) # 0

# same for testing dataset
columnNACounts <- colSums(is.na(testing))  
# columnNACounts 
# after checking columnNACounts , we noticed:
# most columns with NA values have sum of NA values exceeeds 20
badColumns <- columnNACounts >= 20                
cleanTestingdata <- testing[!badColumns]       
sum(is.na(cleanTestingdata)) # 0                   
```

## Feature Selection

```{r, echo=TRUE}
# remove the first 6 columns as they contain user name and time stamps
# which are not useful to the classifier
cleanTrainingdata <- cleanTrainingdata[, c(7:60)] 
cleanTestingdata <- cleanTestingdata[, c(7:60)]
dim(cleanTrainingdata) # [1] 19622    54
dim(cleanTestingdata)  # [1] 20 54
```

### Exploratory Data Analysis
```{r, echo=TRUE}
  plot(cleanTrainingdata$classe,col=rainbow(5),main = "classe frequency plot")
  attach(cleanTrainingdata)
  # plot scatter plot matrices to determine relationship: Linear or Nonlinear
  pairs(classe~num_window+roll_arm+pitch_arm,data=cleanTrainingdata, 
   main="Simple Scatterplot Matrix")
  pairs(classe~roll_belt+pitch_belt+yaw_belt,data=cleanTrainingdata, 
   main="Simple Scatterplot Matrix")
```
From the above analysis, we may conclude that the relation is nonlinear

Now we start partitioning the data:

### Partition cleaned training data : A training set and a cross validation set.
```{r, echo=TRUE, cache=TRUE}
library(caret)
inTrain <- createDataPartition(y = cleanTrainingdata$classe, p = 0.6, list = FALSE)
trainingdata <- cleanTrainingdata[inTrain, ]
crossval <- cleanTrainingdata[-inTrain, ]
```

### Fit a random forest predictor relating the factor variable classe to the remaining variables.
```{r, echo=TRUE, cache=TRUE}

cvCtrl <- trainControl(method = "cv", number = 5, allowParallel = TRUE, verboseIter = TRUE)
# Build the model using 5-fold cross validation
model <- train(classe ~ ., data = trainingdata, method = "rf", trControl = cvCtrl)

```
### To Check the importance of features

```{r, echo=TRUE}
vimp <- varImp(model)
print(vimp)
```


### Calculate in-sample accuracy

Here, we calculate the in sample accuracy which is the prediction accuracy of our model on the training data set.


```{r, echo=TRUE, cache=TRUE}
training_pred <- predict(model, trainingdata)# We build the model using 5-fold cross validation.
confusionMatrix(training_pred, trainingdata$classe)
```
Thus, from the above confusion matrix, sample accuracy value is 100%.

### Calculate out-of-sample accuracy
```{r, echo=TRUE}
testing_pred <- predict(model, crossval)
confusionMatrix(testing_pred, crossval$classe)

```

The out-of-sample accuracy is 99%.
Now, we apply the above model to the clean testing data (20 cases)

### Testing our model with new data (20 cases)
```{r, echo=TRUE}
answers <- predict(model, testing)
answers <- as.character(answers)
answers
```





